{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install librosa==0.8.1\n!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# json response\n!gdown --id 1OsWBkQp610873Eb_d8QbYG6f7DGXbvXU\n# json um_uh.mp3\n!gdown --id 1vA66CXTxx2Kugyv-O2P_BpG8H1USZAhp","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:40:33.152696Z","iopub.execute_input":"2023-04-06T16:40:33.153150Z","iopub.status.idle":"2023-04-06T16:40:38.806753Z","shell.execute_reply.started":"2023-04-06T16:40:33.153109Z","shell.execute_reply":"2023-04-06T16:40:38.805489Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.7/site-packages/gdown/cli.py:130: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom: https://drive.google.com/uc?id=1OsWBkQp610873Eb_d8QbYG6f7DGXbvXU\nTo: /kaggle/working/response_1680775446119.json\n100%|██████████████████████████████████████| 4.44k/4.44k [00:00<00:00, 4.58MB/s]\n/opt/conda/lib/python3.7/site-packages/gdown/cli.py:130: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom: https://drive.google.com/uc?id=1vA66CXTxx2Kugyv-O2P_BpG8H1USZAhp\nTo: /kaggle/working/um_uh.mp3\n100%|████████████████████████████████████████| 476k/476k [00:00<00:00, 83.6MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# !gdown --id 1WfnmYuP58qC_68dKIcYgqqbPc_Usm6yU","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:40:52.136415Z","iopub.execute_input":"2023-04-06T16:40:52.136876Z","iopub.status.idle":"2023-04-06T16:40:52.142581Z","shell.execute_reply.started":"2023-04-06T16:40:52.136832Z","shell.execute_reply":"2023-04-06T16:40:52.141204Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1WfnmYuP58qC_68dKIcYgqqbPc_Usm6yU/view?usp=share_link","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://drive.google.com/drive/folders/1fLm772uCjwhDD6GJxigvDPNGATLvtBiD?usp=share_link","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:41:43.080705Z","iopub.execute_input":"2023-04-06T16:41:43.081191Z","iopub.status.idle":"2023-04-06T16:41:43.087528Z","shell.execute_reply.started":"2023-04-06T16:41:43.081153Z","shell.execute_reply":"2023-04-06T16:41:43.086059Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import json\nimport subprocess\nimport soundfile\nimport torchaudio\nimport librosa\nimport torch.nn as nn\nimport numpy as np\n\nfrom transformers import AutoConfig, Wav2Vec2Processor","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:42:22.163474Z","iopub.execute_input":"2023-04-06T16:42:22.163955Z","iopub.status.idle":"2023-04-06T16:42:29.190554Z","shell.execute_reply.started":"2023-04-06T16:42:22.163910Z","shell.execute_reply":"2023-04-06T16:42:29.189328Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"SAMPLE_RATE = 16000","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:42:32.151842Z","iopub.execute_input":"2023-04-06T16:42:32.152286Z","iopub.status.idle":"2023-04-06T16:42:32.157798Z","shell.execute_reply.started":"2023-04-06T16:42:32.152247Z","shell.execute_reply":"2023-04-06T16:42:32.156480Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def ffmpeg_convert(input_audiofile, output_audiofile, sr=SAMPLE_RATE):\n    \"\"\"\n    Convert an audio file to a resampled audio file with the desired\n    sampling rate specified by `sr`.\n    Parameters\n    ----------\n    input_audiofile : string\n            Path to the video or audio file to be resampled.\n    output_audiofile\n            Path for saving the resampled audio file. Should have .wav extension.\n    sr : int\n            The sampling rate to use for resampling (e.g. 16000, 44100, 48000).\n    Returns\n    -------\n    completed_process : subprocess.CompletedProcess\n            A process completion object. If completed_process.returncode is 0 it\n            means the process completed successfully. 1 means it failed.\n    \"\"\"\n\n    # fmpeg command\n    cmd = [\"ffmpeg\", \"-i\", input_audiofile, \"-ac\", \"1\", \"-af\", \"aresample=resampler=soxr\", \"-ar\", str(sr), \"-y\", output_audiofile]\n    # print(' '.join(cmd))\n    # return\n    completed_process = subprocess.run(cmd)\n\n    # confrim process completed successfully\n    assert completed_process.returncode == 0\n\n    # confirm new file has desired sample rate\n    assert soundfile.info(output_audiofile).samplerate == sr","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:42:32.795308Z","iopub.execute_input":"2023-04-06T16:42:32.796657Z","iopub.status.idle":"2023-04-06T16:42:32.806749Z","shell.execute_reply.started":"2023-04-06T16:42:32.796594Z","shell.execute_reply":"2023-04-06T16:42:32.805440Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# global name_id = 0\ndef cut_file(src_filepath, tar_filepath, start_time, end_time):\n#     tar_filepath = src_filepath_wo + str(name_id)\n    cut_cmd = [\"ffmpeg\", \"-i\", src_filepath, \"-ss\", str(start_time), \"-to\", str(end_time), tar_filepath]\n    print(' '.join(cut_cmd))\n    completed_process = subprocess.run(cut_cmd)\n    assert completed_process.returncode == 0\n#     return tar_filepath","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:42:33.918037Z","iopub.execute_input":"2023-04-06T16:42:33.918475Z","iopub.status.idle":"2023-04-06T16:42:33.925142Z","shell.execute_reply.started":"2023-04-06T16:42:33.918438Z","shell.execute_reply":"2023-04-06T16:42:33.924188Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"json_file = open(\"response_1680775446119.json\")\ndata_str = json.load(json_file)\ndata = json.loads(data_str)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:42:34.447599Z","iopub.execute_input":"2023-04-06T16:42:34.448630Z","iopub.status.idle":"2023-04-06T16:42:34.455993Z","shell.execute_reply.started":"2023-04-06T16:42:34.448561Z","shell.execute_reply":"2023-04-06T16:42:34.455011Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# !rm -rf gaps\n!mkdir gaps_mp3\n!mkdir gaps_wav","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:42:51.797373Z","iopub.execute_input":"2023-04-06T16:42:51.797841Z","iopub.status.idle":"2023-04-06T16:42:54.001590Z","shell.execute_reply.started":"2023-04-06T16:42:51.797805Z","shell.execute_reply":"2023-04-06T16:42:53.999538Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"gaps = []\nstart_gap = 0\nend_gap = 0\ncnt = 1\nfor word in data['words']:\n#     data[]\n    \n    end_gap = word['start']\n    if end_gap - start_gap < 0.2:\n        continue\n    cut_file('um_uh.mp3', f'gaps_mp3/um_uh_{cnt}.mp3', start_gap, end_gap)\n    ffmpeg_convert(f'gaps_mp3/um_uh_{cnt}.mp3', f'gaps_wav/um_uh_{cnt}.wav')\n    print(\"gap: \", start_gap, end_gap)\n    print(\"word: \", word['start'], word['end'])\n    start_gap = word['end']\n    cnt += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ffmpeg -i um_uh.mp3 -ss 0 -to 1.3 gaps/um_uh_1.mp3","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:43:05.832752Z","iopub.execute_input":"2023-04-06T16:43:05.833233Z","iopub.status.idle":"2023-04-06T16:43:05.838963Z","shell.execute_reply.started":"2023-04-06T16:43:05.833180Z","shell.execute_reply":"2023-04-06T16:43:05.837745Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !tree","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:43:16.846763Z","iopub.execute_input":"2023-04-06T16:43:16.847313Z","iopub.status.idle":"2023-04-06T16:43:16.852743Z","shell.execute_reply.started":"2023-04-06T16:43:16.847259Z","shell.execute_reply":"2023-04-06T16:43:16.851753Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# !zip -r gaps gaps_wav ","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:43:24.185952Z","iopub.execute_input":"2023-04-06T16:43:24.186434Z","iopub.status.idle":"2023-04-06T16:43:24.191871Z","shell.execute_reply.started":"2023-04-06T16:43:24.186389Z","shell.execute_reply":"2023-04-06T16:43:24.190567Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Optional, Tuple\nimport torch\nfrom transformers.file_utils import ModelOutput\n\n\n@dataclass\nclass SpeechClassifierOutput(ModelOutput):\n    loss: Optional[torch.FloatTensor] = None\n    logits: torch.FloatTensor = None\n    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n    attentions: Optional[Tuple[torch.FloatTensor]] = None\n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:48:23.575249Z","iopub.execute_input":"2023-04-06T16:48:23.576036Z","iopub.status.idle":"2023-04-06T16:48:23.588723Z","shell.execute_reply.started":"2023-04-06T16:48:23.575963Z","shell.execute_reply":"2023-04-06T16:48:23.587701Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n\nfrom transformers.models.wav2vec2.modeling_wav2vec2 import (\n    Wav2Vec2PreTrainedModel,\n    Wav2Vec2Model\n)\n\n\nclass Wav2Vec2ClassificationHead(nn.Module):\n    \"\"\"Head for wav2vec classification task.\"\"\"\n\n    def __init__(self, config):\n        super().__init__()\n        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n\n    def forward(self, features, **kwargs):\n        x = features\n        x = self.out_proj(x)\n        return x\n\n\nclass Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        self.pooling_mode = config.pooling_mode\n        self.config = config\n\n        self.wav2vec2 = Wav2Vec2Model(config)\n        self.classifier = Wav2Vec2ClassificationHead(config)\n\n        self.init_weights()\n\n    def freeze_feature_extractor(self):\n        self.wav2vec2.feature_extractor._freeze_parameters()\n\n    def merged_strategy(\n            self,\n            hidden_states,\n            mode=\"mean\"\n    ):\n        if mode == \"mean\":\n            outputs = torch.mean(hidden_states, dim=1)\n        elif mode == \"sum\":\n            outputs = torch.sum(hidden_states, dim=1)\n        elif mode == \"max\":\n            outputs = torch.max(hidden_states, dim=1)[0]\n        else:\n            raise Exception(\n                \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n\n        return outputs\n\n    def forward(\n            self,\n            input_values,\n            attention_mask=None,\n            output_attentions=None,\n            output_hidden_states=None,\n            return_dict=None,\n            labels=None,\n    ):\n        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n        outputs = self.wav2vec2(\n            input_values,\n            attention_mask=attention_mask,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n        hidden_states = outputs[0]\n        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n#         print(\"hidden_states.shape: \", hidden_states.shape)\n        logits = self.classifier(hidden_states)\n#         print(\"logits: \", logits)\n\n        loss = None\n        if labels is not None:\n            if self.config.problem_type is None:\n                if self.num_labels == 1:\n                    self.config.problem_type = \"regression\"\n                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n                    self.config.problem_type = \"single_label_classification\"\n                else:\n                    self.config.problem_type = \"multi_label_classification\"\n\n            if self.config.problem_type == \"regression\":\n                loss_fct = MSELoss()\n                loss = loss_fct(logits.view(-1, self.num_labels), labels)\n            elif self.config.problem_type == \"single_label_classification\":\n                loss_fct = CrossEntropyLoss()\n                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n            elif self.config.problem_type == \"multi_label_classification\":\n                loss_fct = BCEWithLogitsLoss()\n                loss = loss_fct(logits, labels)\n\n        if not return_dict:\n            output = (logits,) + outputs[2:]\n            return ((loss,) + output) if loss is not None else output\n\n        return SpeechClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=outputs.hidden_states,\n            attentions=outputs.attentions,\n        )\n","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:48:24.985159Z","iopub.execute_input":"2023-04-06T16:48:24.985881Z","iopub.status.idle":"2023-04-06T16:48:25.008745Z","shell.execute_reply.started":"2023-04-06T16:48:24.985829Z","shell.execute_reply":"2023-04-06T16:48:25.007383Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name_or_path = \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"\npooling_mode = \"mean\"\nlabel_list = ['Breath', 'Laughter', 'Music', 'Uh', 'Um', 'Words']\nnum_labels = 6","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:48:43.973539Z","iopub.execute_input":"2023-04-06T16:48:43.974705Z","iopub.status.idle":"2023-04-06T16:48:43.979652Z","shell.execute_reply.started":"2023-04-06T16:48:43.974663Z","shell.execute_reply":"2023-04-06T16:48:43.978353Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\n    model_name_or_path,\n    num_labels=num_labels,\n    label2id={label: i for i, label in enumerate(label_list)},\n    id2label={i: label for i, label in enumerate(label_list)},\n    finetuning_task=\"wav2vec2_clf\",\n)\nsetattr(config, 'pooling_mode', pooling_mode)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:48:44.157901Z","iopub.execute_input":"2023-04-06T16:48:44.158734Z","iopub.status.idle":"2023-04-06T16:48:44.458636Z","shell.execute_reply.started":"2023-04-06T16:48:44.158692Z","shell.execute_reply":"2023-04-06T16:48:44.457128Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"label2id = {label: i for i, label in enumerate(label_list)},\nlabel2id","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:51:13.815431Z","iopub.execute_input":"2023-04-06T16:51:13.816252Z","iopub.status.idle":"2023-04-06T16:51:13.826631Z","shell.execute_reply.started":"2023-04-06T16:51:13.816189Z","shell.execute_reply":"2023-04-06T16:51:13.825450Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"({'Breath': 0, 'Laughter': 1, 'Music': 2, 'Uh': 3, 'Um': 4, 'Words': 5},)"},"metadata":{}}]},{"cell_type":"code","source":"model_loaded = Wav2Vec2ForSpeechClassification.from_pretrained(\n    model_name_or_path,\n    config=config,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:48:45.315430Z","iopub.execute_input":"2023-04-06T16:48:45.315861Z","iopub.status.idle":"2023-04-06T16:48:50.802912Z","shell.execute_reply.started":"2023-04-06T16:48:45.315826Z","shell.execute_reply":"2023-04-06T16:48:50.801585Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-russian were not used when initializing Wav2Vec2ForSpeechClassification: ['lm_head.weight', 'lm_head.bias']\n- This IS expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForSpeechClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForSpeechClassification were not initialized from the model checkpoint at jonatasgrosman/wav2vec2-large-xlsr-53-russian and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# model link\n!gdown --id 1cPMPJPgHZ_s5jT-GU65mwCkjBSckNB0j","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:48:50.805342Z","iopub.execute_input":"2023-04-06T16:48:50.805697Z","iopub.status.idle":"2023-04-06T16:49:01.587927Z","shell.execute_reply.started":"2023-04-06T16:48:50.805661Z","shell.execute_reply":"2023-04-06T16:49:01.586812Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.7/site-packages/gdown/cli.py:130: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  category=FutureWarning,\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1cPMPJPgHZ_s5jT-GU65mwCkjBSckNB0j\nFrom (redirected): https://drive.google.com/uc?id=1cPMPJPgHZ_s5jT-GU65mwCkjBSckNB0j&confirm=t&uuid=9e0f8862-ba3e-4228-9510-1a74f3ebfd4a\nTo: /kaggle/working/interjections_clf_cpu.pt\n100%|███████████████████████████████████████| 1.26G/1.26G [00:06<00:00, 188MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"model_loaded.load_state_dict(torch.load('interjections_clf_cpu.pt'))","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:49:01.589623Z","iopub.execute_input":"2023-04-06T16:49:01.590144Z","iopub.status.idle":"2023-04-06T16:49:02.790404Z","shell.execute_reply.started":"2023-04-06T16:49:01.590092Z","shell.execute_reply":"2023-04-06T16:49:02.789161Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# model_name_or_path = \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"\nprocessor = Wav2Vec2Processor.from_pretrained(model_name_or_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:49:02.793397Z","iopub.execute_input":"2023-04-06T16:49:02.793770Z","iopub.status.idle":"2023-04-06T16:49:04.241514Z","shell.execute_reply.started":"2023-04-06T16:49:02.793737Z","shell.execute_reply":"2023-04-06T16:49:04.240001Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def speech_file_to_array_fn(file_path):\n    speech_array, sampling_rate = torchaudio.load(file_path)\n    speech_array = speech_array.squeeze().numpy()\n    speech_array = librosa.resample(np.asarray(speech_array), sampling_rate, processor.feature_extractor.sampling_rate)\n\n#     batch[\"speech\"] = \n    return speech_array\n\n\ndef predict(speech_array, model, device):\n    features = processor(speech_array, sampling_rate=processor.feature_extractor.sampling_rate, return_tensors=\"pt\", padding=True, return_attention_mask=True)\n\n#     print(features)\n    input_values = features.input_values.to(device)\n    attention_mask = features.attention_mask.to(device)\n    \n    with torch.no_grad():\n        logits = model(input_values, attention_mask).logits #attention_mask\n\n    pred_ids = torch.argmax(logits, dim=-1).detach().cpu().numpy()\n#     batch[\"predicted\"] = pred_ids\n    return pred_ids","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:49:04.242990Z","iopub.execute_input":"2023-04-06T16:49:04.243388Z","iopub.status.idle":"2023-04-06T16:49:04.252736Z","shell.execute_reply.started":"2023-04-06T16:49:04.243349Z","shell.execute_reply":"2023-04-06T16:49:04.251393Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:49:04.254330Z","iopub.execute_input":"2023-04-06T16:49:04.254778Z","iopub.status.idle":"2023-04-06T16:49:05.181721Z","shell.execute_reply.started":"2023-04-06T16:49:04.254731Z","shell.execute_reply":"2023-04-06T16:49:05.180425Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:49:05.184016Z","iopub.execute_input":"2023-04-06T16:49:05.184531Z","iopub.status.idle":"2023-04-06T16:49:06.745163Z","shell.execute_reply.started":"2023-04-06T16:49:05.184479Z","shell.execute_reply":"2023-04-06T16:49:06.743555Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:49:06.746611Z","iopub.execute_input":"2023-04-06T16:49:06.746983Z","iopub.status.idle":"2023-04-06T16:49:08.816413Z","shell.execute_reply.started":"2023-04-06T16:49:06.746950Z","shell.execute_reply":"2023-04-06T16:49:08.815289Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"array([3])"},"metadata":{}}]},{"cell_type":"code","source":"for idx in range(1, 15):\n    speech_arr = speech_file_to_array_fn(f\"gaps_wav/um_uh_{idx}.wav\")\n    print(idx, \": \", predict(speech_arr, model_loaded, device))","metadata":{"execution":{"iopub.status.busy":"2023-04-06T16:53:14.893184Z","iopub.execute_input":"2023-04-06T16:53:14.893662Z","iopub.status.idle":"2023-04-06T16:53:22.110292Z","shell.execute_reply.started":"2023-04-06T16:53:14.893626Z","shell.execute_reply":"2023-04-06T16:53:22.108681Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"1 :  [3]\n2 :  [5]\n3 :  [4]\n4 :  [5]\n5 :  [4]\n6 :  [5]\n7 :  [5]\n8 :  [5]\n9 :  [3]\n10 :  [5]\n11 :  [5]\n12 :  [5]\n13 :  [2]\n14 :  [5]\n","output_type":"stream"}]},{"cell_type":"code","source":"label2id = {label: i for i, label in enumerate(label_list)},\nlabel2id","metadata":{"execution":{"iopub.status.busy":"2023-04-06T17:55:57.236179Z","iopub.execute_input":"2023-04-06T17:55:57.237225Z","iopub.status.idle":"2023-04-06T17:55:57.247312Z","shell.execute_reply.started":"2023-04-06T17:55:57.237153Z","shell.execute_reply":"2023-04-06T17:55:57.245937Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"({'Breath': 0, 'Laughter': 1, 'Music': 2, 'Uh': 3, 'Um': 4, 'Words': 5},)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}